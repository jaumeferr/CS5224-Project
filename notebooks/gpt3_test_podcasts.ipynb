{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from pytube import YouTube\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'j:\\\\NUS Workspace\\\\CS5224 - Cloud Comp\\\\CS5224-Project\\\\notebooks\\\\test_video.mp4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get video transcription\n",
    "model = whisper.load_model('base')\n",
    "v_url = \"https://www.youtube.com/watch?v=DuaTGng9tRU\"\n",
    "youtube_video = YouTube(v_url) # Select YT video\n",
    "audio_stream_set = youtube_video.streams.filter(only_audio = True)\n",
    "audio_stream = audio_stream_set.first() # Select quality audio stream\n",
    "audio_stream.download(filename = 'test_video.mp4') # Download video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe and save text as csv divided by sentences\n",
    "\n",
    "import os\n",
    "print(os.path.isfile('j:\\\\NUS Workspace\\\\CS5224 - Cloud Comp\\\\CS5224-Project\\\\notebooks\\\\test_video.mp4'))\n",
    "path = 'j:\\\\NUS Workspace\\\\CS5224 - Cloud Comp\\\\CS5224-Project\\\\notebooks\\\\test_video.mp4'\n",
    "t_model = whisper.transcribe(model= model, audio= path, fp16 = False) # Get transcript\n",
    "t_model\n",
    "# Tokenize and save as csv file\n",
    "nltk.download('punkt')  # download the NLTK tokenizer\n",
    "transcript = t_model['text']\n",
    "# create a Pandas DataFrame with one row for each sentence\n",
    "trans_df = pd.DataFrame({'sentence': nltk.sent_tokenize(transcript)})\n",
    "# add a new column with the length of each sentence\n",
    "trans_df['sentence_length'] = trans_df['sentence'].apply(len)\n",
    "# print the DataFrame\n",
    "print(trans_df)\n",
    "# save the DataFrame to a CSV file\n",
    "trans_df.to_csv('video_text.csv', index=False)\n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('video_text.csv')\n",
    "df = df.set_index([\"sentence\", \"sentence_length\"])\n",
    "print(f\"{len(df)} rows in the data.\")\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the transcript and query embeddings\n",
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "prompt = \"Why should you start being selfish?\"\n",
    "\n",
    "def get_embedding(text: str, model: str=EMBEDDING_MODEL) -> list[float]:\n",
    "    result = openai.Embedding.create(\n",
    "      model=model,\n",
    "      input=text\n",
    "    )\n",
    "    return result[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def compute_doc_embeddings(df: pd.DataFrame) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "    \n",
    "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        idx: get_embedding(r.content) for idx, r in df.iterrows()\n",
    "    }\n",
    "\n",
    "def load_embeddings(fname: str) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Read the document embeddings and their keys from a CSV.\n",
    "    \n",
    "    fname is the path to a CSV with exactly these named columns: \n",
    "        \"title\", \"heading\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(fname, header=0)\n",
    "    max_dim = max([int(c) for c in df.columns if c != \"title\" and c != \"heading\"])\n",
    "    return {\n",
    "           (r.title, r.heading): [r[str(i)] for i in range(max_dim + 1)] for _, r in df.iterrows()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\"\n",
    "test_emb = get_embedding(prompt, EMBEDDING_MODEL)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** RESULT ***\n",
    "\n",
    "{\n",
    "  \"data\": [\n",
    "    {\n",
    "      \"embedding\": [\n",
    "        -0.006929283495992422,\n",
    "        -0.005336422007530928,\n",
    "        ...\n",
    "        -4.547132266452536e-05,\n",
    "        -0.024047505110502243\n",
    "      ],\n",
    "      \"index\": 0,\n",
    "      \"object\": \"embedding\"\n",
    "    }\n",
    "  ],\n",
    "  \"model\": \"text-embedding-ada-002\",\n",
    "  \"object\": \"list\",\n",
    "  \"usage\": {\n",
    "    \"prompt_tokens\": 5,\n",
    "    \"total_tokens\": 5\n",
    "  }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14a9cbf84dd4a29b46cdff894ec5e0ef4cc44a632636ec2c548fb4524f05c5e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
